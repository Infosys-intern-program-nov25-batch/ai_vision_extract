{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ba690655",
      "metadata": {
        "id": "ba690655"
      },
      "source": [
        "### Data Preprocessing Pipeline for Image Segmentation\n",
        "- We are developing a simple data preprocessing pipeline using OpenCV and PyTorch for image segmentation tasks.\n",
        "- This pipeline includes loading an image and its corresponding mask, resizing, normalization, augmentation (random horizontal flip), and converting to PyTorch tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0VnBcvI5iWgm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VnBcvI5iWgm",
        "outputId": "12b44dfb-f010-492c-8757-68902ab77b43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6753a5f7",
      "metadata": {
        "id": "6753a5f7"
      },
      "source": [
        "#### 1. Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4acc46c0",
      "metadata": {
        "id": "4acc46c0"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "774affca",
      "metadata": {
        "id": "774affca"
      },
      "source": [
        "#### 2. Load image and mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HR4yB6d1iJqQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR4yB6d1iJqQ",
        "outputId": "048f33ac-b77e-47b9-d758-ccd9fb875e5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image shape: (425, 640, 3), Mask shape: (425, 640)\n"
          ]
        }
      ],
      "source": [
        "def load_image_and_mask(image_path, mask_path):\n",
        "    # Load image in BGR, convert to RGB\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Load mask in grayscale (assumed: 0 = background, >0 = subject)\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "# Example usage\n",
        "image_path = \"/000000000034.jpg\"\n",
        "mask_path  = \"/000000000034.jpg\"\n",
        "\n",
        "image, mask = load_image_and_mask(image_path, mask_path)\n",
        "print(f\"Image shape: {image.shape}, Mask shape: {mask.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4181f76",
      "metadata": {
        "id": "d4181f76"
      },
      "source": [
        "- `cv2.imread(image_path)` loads the image in BGR format (OpenCV default).\n",
        "\n",
        "- `cv2.cvtColor(..., cv2.COLOR_BGR2RGB)` converts it to RGB so it matches the usual PyTorch convention.\n",
        "\n",
        "- `cv2.imread(..., cv2.IMREAD_GRAYSCALE)` loads the mask as a single-channel grayscale image (0 for background, non-zero for subject)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e11d7da",
      "metadata": {
        "id": "6e11d7da"
      },
      "source": [
        "#### 3. Resize image and mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PiyWwA06iKxB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiyWwA06iKxB",
        "outputId": "ebabbda0-e712-4dc2-e377-ba9764700014"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resized image shape: (256, 256, 3), mask shape: (256, 256)\n"
          ]
        }
      ],
      "source": [
        "def resize_image_and_mask(image, mask, target_size=(256, 256)):\n",
        "    # Resize image using bilinear interpolation\n",
        "    image_resized = cv2.resize(image, target_size, interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    # Resize mask using nearest neighbor (to avoid blurring class boundaries)\n",
        "    mask_resized = cv2.resize(mask, target_size, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    return image_resized, mask_resized\n",
        "\n",
        "# Example usage\n",
        "target_size = (256, 256)\n",
        "image_resized, mask_resized = resize_image_and_mask(image, mask, target_size)\n",
        "print(f\"Resized image shape: {image_resized.shape}, mask shape: {mask_resized.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "427c5594",
      "metadata": {
        "id": "427c5594"
      },
      "source": [
        "- `cv2.INTER_LINEAR` is good for images (smooth resizing).\n",
        "\n",
        "- `cv2.INTER_NEAREST` is used for masks to preserve sharp boundaries (no interpolation between classes).\n",
        "\n",
        "- `target_size` is usually a tuple like `(H, W)` or `(W, H)`; OpenCV uses `(width, height)`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76052787",
      "metadata": {
        "id": "76052787"
      },
      "source": [
        "#### 4. Normalize image to and convert to float"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sipGkVQ3iL0p",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sipGkVQ3iL0p",
        "outputId": "52f12635-be85-4a82-8f5c-e498bd774087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image dtype: float32, range: [0.000, 0.992]\n"
          ]
        }
      ],
      "source": [
        "def normalize_image(image):\n",
        "    # Convert to float32 and scale to [0, 1]\n",
        "    image_float = image.astype(np.float32) / 255.0\n",
        "    return image_float\n",
        "\n",
        "# Example usage\n",
        "image_normalized = normalize_image(image_resized)\n",
        "print(f\"Image dtype: {image_normalized.dtype}, range: [{image_normalized.min():.3f}, {image_normalized.max():.3f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e06e4341",
      "metadata": {
        "id": "e06e4341"
      },
      "source": [
        "- Converts the image from uint8 (0–255) to float32 (0.0–1.0).\n",
        "\n",
        "- This is needed before applying PyTorch normalization transforms."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e85061d",
      "metadata": {
        "id": "8e85061d"
      },
      "source": [
        "#### 5. Apply random horizontal flip (augmentation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fpITZGg3iNbx",
      "metadata": {
        "id": "fpITZGg3iNbx"
      },
      "outputs": [],
      "source": [
        "def random_horizontal_flip(image, mask, p=0.5):\n",
        "    if np.random.rand() < p:\n",
        "        image = np.flip(image, axis=1)\n",
        "        mask  = np.flip(mask,  axis=1)\n",
        "    return image, mask\n",
        "\n",
        "# Example usage\n",
        "image_aug, mask_aug = random_horizontal_flip(image_normalized, mask_resized, p=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfcb65b9",
      "metadata": {
        "id": "cfcb65b9"
      },
      "source": [
        "- Flips both image and mask horizontally with probability p.\n",
        "\n",
        "- This is a simple data augmentation that helps the model generalize better.\n",
        "\n",
        "- Always flip the mask in the same way as the image so the labels stay aligned."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d3db28a",
      "metadata": {
        "id": "5d3db28a"
      },
      "source": [
        "#### 6. Convert to PyTorch tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b3WuGBoiOZ4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b3WuGBoiOZ4",
        "outputId": "700eb523-7d74-44a5-aef2-eaf20e2325fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image tensor shape: torch.Size([3, 256, 256]), mask tensor shape: torch.Size([256, 256])\n"
          ]
        }
      ],
      "source": [
        "def to_tensor(image, mask):\n",
        "    # Convert image: HWC → CHW and to tensor\n",
        "    image_tensor = torch.from_numpy(image).permute(2, 0, 1)  # HWC → CHW\n",
        "    mask_tensor  = torch.from_numpy(mask).long()              # mask as long tensor\n",
        "\n",
        "    return image_tensor, mask_tensor\n",
        "\n",
        "# Example usage\n",
        "image_tensor, mask_tensor = to_tensor(image_aug, mask_aug)\n",
        "print(f\"Image tensor shape: {image_tensor.shape}, mask tensor shape: {mask_tensor.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04cbb7b1",
      "metadata": {
        "id": "04cbb7b1"
      },
      "source": [
        "- `permute(2, 0, 1)` changes the order from `(H, W, C)` to `(C, H, W)` as expected by PyTorch models.\n",
        "\n",
        "- `mask` is converted to `long` (int64) because segmentation masks are class indices (not floats)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a14b9d2",
      "metadata": {
        "id": "1a14b9d2"
      },
      "source": [
        "#### 7. Normalize image using ImageNet stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LxScjVd3iPTa",
      "metadata": {
        "id": "LxScjVd3iPTa"
      },
      "outputs": [],
      "source": [
        "# Define normalization transform (ImageNet mean/std)\n",
        "normalize = transforms.Normalize(\n",
        "    mean=[0.485, 0.456, 0.406],\n",
        "    std=[0.229, 0.224, 0.225]\n",
        ")\n",
        "\n",
        "# Apply normalization\n",
        "image_normalized_tensor = normalize(image_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "257a359d",
      "metadata": {
        "id": "257a359d"
      },
      "source": [
        "- Normalizes each channel using ImageNet statistics (common for models like ResNet, VGG, etc.).\n",
        "\n",
        "- This helps the model train faster and more stably.\n",
        "\n",
        "- Only applied to the image; the mask is left as-is."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7bcb28a",
      "metadata": {
        "id": "b7bcb28a"
      },
      "source": [
        "#### 8. Convert mask to binary (subject vs background)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uMP3BrTwiQe4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMP3BrTwiQe4",
        "outputId": "69d90747-ab23-4dba-9390-94c826c2fe17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique values in mask: tensor([0, 1])\n"
          ]
        }
      ],
      "source": [
        "def make_binary_mask(mask_tensor):\n",
        "    # Convert any non-zero value to 1 (subject), 0 remains background\n",
        "    binary_mask = (mask_tensor > 0).long()\n",
        "    return binary_mask\n",
        "\n",
        "# Example usage\n",
        "binary_mask = make_binary_mask(mask_tensor)\n",
        "print(f\"Unique values in mask: {torch.unique(binary_mask)}\")  # Should be tensor([0, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba96b5df",
      "metadata": {
        "id": "ba96b5df"
      },
      "source": [
        "- Converts a multi-class mask into a binary mask:\n",
        "\n",
        "  - `0` → background\n",
        "\n",
        "  - `>0` → subject (set to 1)\n",
        "\n",
        "- Useful if the original mask has multiple object classes but the task is just “subject vs background”.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d645902e",
      "metadata": {
        "id": "d645902e"
      },
      "source": [
        "#### Task: Implement the full pipeline and execute it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ZUB_F_QF93Kr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUB_F_QF93Kr",
        "outputId": "a536756b-d538-41b7-e57a-cad7084c09ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating dummy data...\n",
            "\n",
            "--- Pipeline Success ---\n",
            "Final Image Tensor Shape: torch.Size([3, 256, 256])\n",
            "Final Mask Tensor Shape:  torch.Size([256, 256])\n",
            "Mask Unique Values:       tensor([0, 1])\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "class SegmentationPipeline:\n",
        "    def __init__(self, target_size=(256, 256), augment=True):\n",
        "        \"\"\"\n",
        "        Initialize pipeline parameters.\n",
        "        Args:\n",
        "            target_size (tuple): Target (width, height) for resizing.\n",
        "            augment (bool): Whether to apply data augmentation (random flip).\n",
        "        \"\"\"\n",
        "        self.target_size = target_size\n",
        "        self.augment = augment\n",
        "\n",
        "        # Define normalization (ImageNet stats)\n",
        "        self.normalize_transform = transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        )\n",
        "\n",
        "    def load_data(self, image_path, mask_path):\n",
        "        \"\"\"Loads image and mask from disk.\"\"\"\n",
        "        # Load image in BGR, convert to RGB\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            raise FileNotFoundError(f\"Could not load image: {image_path}\")\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Load mask in grayscale\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if mask is None:\n",
        "            raise FileNotFoundError(f\"Could not load mask: {mask_path}\")\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def resize(self, image, mask):\n",
        "        \"\"\"Resizes image (bilinear) and mask (nearest neighbor).\"\"\"\n",
        "        image_resized = cv2.resize(image, self.target_size, interpolation=cv2.INTER_LINEAR)\n",
        "        mask_resized = cv2.resize(mask, self.target_size, interpolation=cv2.INTER_NEAREST)\n",
        "        return image_resized, mask_resized\n",
        "\n",
        "    def normalize_to_float(self, image):\n",
        "        \"\"\"Scales pixel values to [0, 1] float32.\"\"\"\n",
        "        return image.astype(np.float32) / 255.0\n",
        "\n",
        "    def apply_augmentation(self, image, mask, p=0.5):\n",
        "        \"\"\"Applies random horizontal flip.\"\"\"\n",
        "        if self.augment and np.random.rand() < p:\n",
        "            image = np.flip(image, axis=1)\n",
        "            mask = np.flip(mask, axis=1)\n",
        "        return image, mask\n",
        "\n",
        "    def to_tensor(self, image, mask):\n",
        "        \"\"\"Converts numpy arrays to PyTorch tensors (CHW format).\"\"\"\n",
        "        # Handle negative strides from flipping\n",
        "        if image.strides[0] < 0 or image.strides[1] < 0:\n",
        "            image = image.copy()\n",
        "        if mask.strides[0] < 0 or mask.strides[1] < 0:\n",
        "            mask = mask.copy()\n",
        "\n",
        "        # HWC -> CHW for image\n",
        "        image_tensor = torch.from_numpy(image).permute(2, 0, 1)\n",
        "        mask_tensor = torch.from_numpy(mask).long()\n",
        "        return image_tensor, mask_tensor\n",
        "\n",
        "    def make_binary_mask(self, mask_tensor):\n",
        "        \"\"\"Converts mask to binary (0 = background, 1 = subject).\"\"\"\n",
        "        return (mask_tensor > 0).long()\n",
        "\n",
        "    def run(self, image_path, mask_path):\n",
        "        \"\"\"Executes the full pipeline on a single image/mask pair.\"\"\"\n",
        "        # 1. Load\n",
        "        img, mask = self.load_data(image_path, mask_path)\n",
        "\n",
        "        # 2. Resize\n",
        "        img, mask = self.resize(img, mask)\n",
        "\n",
        "        # 3. Normalize pixels\n",
        "        img = self.normalize_to_float(img)\n",
        "\n",
        "        # 4. Augment\n",
        "        img, mask = self.apply_augmentation(img, mask)\n",
        "\n",
        "        # 5. Convert to Tensor\n",
        "        img_t, mask_t = self.to_tensor(img, mask)\n",
        "\n",
        "        # 6. Normalize (ImageNet stats)\n",
        "        img_t = self.normalize_transform(img_t)\n",
        "\n",
        "        # 7. Binary Mask\n",
        "        mask_t = self.make_binary_mask(mask_t)\n",
        "\n",
        "        return img_t, mask_t\n",
        "\n",
        "# --- Execution Block ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Create dummy data for demonstration\n",
        "    print(\"Creating dummy data...\")\n",
        "    dummy_img = np.random.randint(0, 255, (425, 640, 3), dtype=np.uint8)\n",
        "    dummy_mask = np.random.randint(0, 2, (425, 640), dtype=np.uint8) * 255\n",
        "    cv2.imwrite(\"test_image.jpg\", dummy_img)\n",
        "    cv2.imwrite(\"test_mask.jpg\", dummy_mask)\n",
        "\n",
        "    # Initialize and run pipeline\n",
        "    pipeline = SegmentationPipeline(target_size=(256, 256))\n",
        "\n",
        "    try:\n",
        "        final_img, final_mask = pipeline.run(\"test_image.jpg\", \"test_mask.jpg\")\n",
        "\n",
        "        print(\"\\n--- Pipeline Success ---\")\n",
        "        print(f\"Final Image Tensor Shape: {final_img.shape}\")\n",
        "        print(f\"Final Mask Tensor Shape:  {final_mask.shape}\")\n",
        "        print(f\"Mask Unique Values:       {torch.unique(final_mask)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86d35a2a",
      "metadata": {
        "id": "86d35a2a"
      },
      "source": [
        "## Define Normalization Transform\n",
        "\n",
        "### Subtask:\n",
        "Ensure the `transforms.Normalize` object (`normalize`) is defined within or accessible by the pipeline function for PyTorch tensor normalization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcb7ee2e",
      "metadata": {
        "id": "bcb7ee2e"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Confirm that the full data preprocessing pipeline has been successfully implemented and tested, producing the desired image and binary mask tensors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8187c7ed",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ank ss (Python 3.12.7)",
      "language": "python",
      "name": "ank-ss"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
