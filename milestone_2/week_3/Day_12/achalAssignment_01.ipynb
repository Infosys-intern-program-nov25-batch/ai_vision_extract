{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Task: Using this sample dataset, create or optimize data preprocessing pipeline using opencv and pytorch and include image mask technique in the pipeline and save the output."
      ],
      "metadata": {
        "id": "-Se1uPLD9S7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CwTRVPN88eC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "186fddbd-b665-49a2-bd36-ed6a86ffdcf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tF86DNFZ8WwJ"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/AI_Vision_Extract_Nov25/data/COCO2017_SAMPLE'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_transform():\n",
        "    # simple wrapper so it behaves like albumentations-style transform\n",
        "    def apply(image, mask):\n",
        "        return {\n",
        "            \"image\": image,\n",
        "            \"mask\": mask\n",
        "        }\n",
        "    return apply\n"
      ],
      "metadata": {
        "id": "thxpVmZuEUOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "-xFtP2j49jQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CocoSampleDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.images = sorted([f for f in os.listdir(image_dir) if f.endswith(\".jpg\")])\n",
        "        self.masks  = sorted([f for f in os.listdir(mask_dir) if f.endswith((\".png\",\".jpg\"))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_name = self.images[idx]\n",
        "        mask_name = self.masks[idx]\n",
        "\n",
        "        img_path = os.path.join(self.image_dir, img_name)\n",
        "        mask_path = os.path.join(self.mask_dir, mask_name)\n",
        "\n",
        "        # read image\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # read mask\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # resize\n",
        "        image = cv2.resize(image, (256, 256))\n",
        "        mask = cv2.resize(mask, (256, 256), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        # binary mask\n",
        "        _, mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        if self.transform:\n",
        "            out = self.transform(image=image, mask=mask)\n",
        "            image = out[\"image\"]\n",
        "            mask  = out[\"mask\"]\n",
        "\n",
        "        # convert to torch\n",
        "        image = torch.from_numpy(image).permute(2,0,1).float() / 255.0\n",
        "        mask  = torch.from_numpy(mask).long()\n",
        "\n",
        "        return {\"image\": image, \"mask\": mask, \"name\": img_name}\n"
      ],
      "metadata": {
        "id": "gkP3iZkoC80n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_output(sample, out_dir):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    img = sample[\"image\"].permute(1,2,0).numpy()*255\n",
        "    img = img.astype(np.uint8)\n",
        "\n",
        "    mask = sample[\"mask\"].numpy().astype(np.uint8)\n",
        "\n",
        "    base = sample[\"name\"].split(\".\")[0]\n",
        "\n",
        "    cv2.imwrite(os.path.join(out_dir, f\"{base}_processed.png\"), img)\n",
        "    cv2.imwrite(os.path.join(out_dir, f\"{base}_mask.png\"), mask)\n",
        "\n",
        "    torch.save(sample, os.path.join(out_dir, f\"{base}.pt\"))\n"
      ],
      "metadata": {
        "id": "IPE_MVgVDyZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline(image_dir, mask_dir, out_dir):\n",
        "\n",
        "    dataset = CocoSampleDataset(\n",
        "        image_dir=image_dir,\n",
        "        mask_dir=mask_dir,\n",
        "        transform=preprocess_transform()\n",
        "    )\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    for batch in tqdm(loader):\n",
        "        sample = {\n",
        "            \"image\": batch[\"image\"][0],\n",
        "            \"mask\": batch[\"mask\"][0],\n",
        "            \"name\": batch[\"name\"][0]\n",
        "        }\n",
        "        save_output(sample, out_dir)\n",
        "\n",
        "    print(\"✔ Processing complete!\")\n"
      ],
      "metadata": {
        "id": "0EedMXrJD1I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = \"/content/drive/MyDrive/AI_Vision_Extract_Nov25/data/COCO2017_SAMPLE\"\n",
        "mask_dir  = \"/content/drive/MyDrive/AI_Vision_Extract_Nov25/data/COCO2017_SAMPLE\"\n",
        "out_dir   = \"/content/drive/MyDrive/AI_Vision_Extract_Nov25/data/COCO2017_SAMPLE\"\n",
        "\n",
        "!mkdir -p \"$out_dir\"\n",
        "\n",
        "run_pipeline(image_dir, mask_dir, out_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo4tpJpsD4e_",
        "outputId": "877e76a3-aa76-4216-f763-dc1fc989a7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00, 11.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔ Processing complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}