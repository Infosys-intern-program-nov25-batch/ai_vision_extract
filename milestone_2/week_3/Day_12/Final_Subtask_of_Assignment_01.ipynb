{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Task: Using this sample dataset, create or optimize data preprocessing pipeline using opencv and pytorch and include image mask technique in the pipeline and save the output."
      ],
      "metadata": {
        "id": "-Se1uPLD9S7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwTRVPN88eC8",
        "outputId": "3fe257f0-b43e-4559-cde0-6d0afa50f1bf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tF86DNFZ8WwJ"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/AI_Vision_Extract_Nov25/data/COCO2017_SAMPLE'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import shutil\n",
        "\n",
        "# --- Configuration ---\n",
        "RAW_DATA_DIR = \"/content/drive/MyDrive/AI_Vision_Extract_Nov25/data/COCO2017_SAMPLE\"\n",
        "PROCESSED_DIR = \"processed_output\"\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "# ==========================================\n",
        "# 1. Helper: Generate Sample Dataset\n",
        "# ==========================================\n",
        "def generate_sample_data(num_images=5):\n",
        "    \"\"\"Creates synthetic images: Green circles on black background.\"\"\"\n",
        "    if os.path.exists(RAW_DATA_DIR):\n",
        "        shutil.rmtree(RAW_DATA_DIR)\n",
        "    os.makedirs(RAW_DATA_DIR)\n",
        "\n",
        "    print(f\"Creating {num_images} sample images...\")\n",
        "    for i in range(num_images):\n",
        "        # Create black background\n",
        "        img = np.zeros((500, 500, 3), dtype=np.uint8)\n",
        "        # Draw a green circle (The object we want to mask/keep)\n",
        "        center = (np.random.randint(100, 400), np.random.randint(100, 400))\n",
        "        radius = np.random.randint(50, 100)\n",
        "        cv2.circle(img, center, radius, (0, 255, 0), -1)\n",
        "\n",
        "        # Add some noise (simulating real world data)\n",
        "        noise = np.random.randint(0, 50, (500, 500, 3), dtype=np.uint8)\n",
        "        img = cv2.add(img, noise)\n",
        "\n",
        "        cv2.imwrite(os.path.join(RAW_DATA_DIR, f\"image_{i}.jpg\"), img)\n",
        "\n",
        "# ==========================================\n",
        "# 2. Optimization: Custom OpenCV Transform\n",
        "# ==========================================\n",
        "class OpenCVMaskAndCrop:\n",
        "    \"\"\"\n",
        "    Custom transform to apply OpenCV masking inside the PyTorch pipeline.\n",
        "    Isolates green objects and blacks out the background.\n",
        "    \"\"\"\n",
        "    def __call__(self, img):\n",
        "        # Convert PIL (PyTorch default) to OpenCV (numpy)\n",
        "        img_np = np.array(img)\n",
        "\n",
        "        # Convert RGB to HSV for better color segmentation\n",
        "        hsv = cv2.cvtColor(img_np, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "        # Define range for Green color\n",
        "        lower_green = np.array([40, 40, 40])\n",
        "        upper_green = np.array([80, 255, 255])\n",
        "\n",
        "        # Create Mask\n",
        "        mask = cv2.inRange(hsv, lower_green, upper_green)\n",
        "\n",
        "        # Bitwise-AND mask and original image\n",
        "        result = cv2.bitwise_and(img_np, img_np, mask=mask)\n",
        "\n",
        "        # Convert back to PIL Image so PyTorch transforms can continue\n",
        "        return Image.fromarray(result)\n",
        "\n",
        "# ==========================================\n",
        "# 3. The Pipeline (Dataset Class)\n",
        "# ==========================================\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.image_files = [f for f in os.listdir(root_dir) if f.endswith('.jpg')]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.image_files[idx])\n",
        "\n",
        "        # Load Image as PIL (Standard for torchvision)\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, self.image_files[idx]\n",
        "\n",
        "# ==========================================\n",
        "# 4. Main Execution\n",
        "# ==========================================\n",
        "def run_pipeline():\n",
        "    # A. Setup\n",
        "    generate_sample_data()\n",
        "    if os.path.exists(PROCESSED_DIR):\n",
        "        shutil.rmtree(PROCESSED_DIR)\n",
        "    os.makedirs(PROCESSED_DIR)\n",
        "\n",
        "    # B. Define the Transformation Pipeline\n",
        "    # 1. Custom Masking -> 2. Resize -> 3. Convert to Tensor -> 4. Normalize\n",
        "    preprocessing_pipeline = transforms.Compose([\n",
        "        OpenCVMaskAndCrop(),  # <--- Our Custom OpenCV step\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        # Normalize (standard ImageNet means/stds)\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # C. Initialize Dataset and Dataloader\n",
        "    dataset = SegmentationDataset(root_dir=RAW_DATA_DIR, transform=preprocessing_pipeline)\n",
        "\n",
        "    # num_workers=2 enables parallel data loading (Optimization)\n",
        "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "    print(f\"\\nStarting pipeline on {len(dataset)} images...\")\n",
        "\n",
        "    # D. Process and Save\n",
        "    for batch_idx, (images, filenames) in enumerate(dataloader):\n",
        "        print(f\"Processing Batch {batch_idx + 1} with shape: {images.shape}\")\n",
        "\n",
        "        # In a real scenario, you would feed 'images' to a model here.\n",
        "        # For this task, we will save the processed tensor output.\n",
        "\n",
        "        for i in range(len(images)):\n",
        "            # Save the tensor data\n",
        "            save_path = os.path.join(PROCESSED_DIR, f\"processed_{filenames[i]}.pt\")\n",
        "            torch.save(images[i], save_path)\n",
        "\n",
        "            # OPTIONAL: Save visual image to verify the mask worked\n",
        "            # We must un-normalize and convert back to image for viewing\n",
        "            inv_normalize = transforms.Normalize(\n",
        "                mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
        "                std=[1/0.229, 1/0.224, 1/0.225]\n",
        "            )\n",
        "            img_vis = inv_normalize(images[i])\n",
        "            img_vis = transforms.ToPILImage()(img_vis)\n",
        "            img_vis.save(os.path.join(PROCESSED_DIR, f\"visual_{filenames[i]}\"))\n",
        "\n",
        "    print(f\"\\nSuccess! Processed data saved to: {os.path.abspath(PROCESSED_DIR)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IX-L4DBA_lJ",
        "outputId": "71a24ac5-f59a-4632-b837-4c4d366fa3e3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating 5 sample images...\n",
            "\n",
            "Starting pipeline on 5 images...\n",
            "Processing Batch 1 with shape: torch.Size([4, 3, 224, 224])\n",
            "Processing Batch 2 with shape: torch.Size([1, 3, 224, 224])\n",
            "\n",
            "Success! Processed data saved to: /content/processed_output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a comprehensive PyTorch + OpenCV hybrid pipeline designed for Data Preprocessing and Object Isolation.\n",
        "\n",
        "This script demonstrates how to mix \"classic\" Computer Vision (OpenCV color thresholding) with modern Deep Learning workflows (PyTorch DataLoaders). It simulates a scenario where you want to train an AI model only on specific objects (green circles) by removing the background before the AI ever sees the image.\n",
        "\n",
        " Here is a breakdown of the four main components of your code:\n",
        " 1. Data Generation (The \"Simulator\")\n",
        " Function:generate_sample_data(num_images=5)\n",
        "\n",
        " Since you might not have a real dataset ready, this function creates a \"synthetic\" one.\n",
        "\n",
        " What it does: It creates a black canvas (np.zeros), draws a green circle on it, and adds random \"noise\" (colored static) to simulate real-world camera imperfections.\n",
        "\n",
        " Why it matters: This is excellent for Unit Testing. If your pipeline works on these simple circles, you know the logic is sound before you try it on complex real-world photos.\n",
        "\n",
        " Key Detail: It uses cv2.add(img, noise). Unlike standard addition (+), OpenCV addition handles \"saturation.\" If a pixel value goes over 255, it stays at 255 (white) rather than wrapping around to 0 (black).\n",
        "\n",
        " 2. The \"Brain\": Custom Segmentation Transform\n",
        "\n",
        " Class: OpenCVMaskAndCrop\n",
        "\n",
        " This is the most critical part of the code. It is a Custom PyTorch Transform.\n",
        "\n",
        " The Problem: PyTorch works with PIL images. OpenCV works with NumPy arrays.\n",
        "\n",
        " The Solution: This class handles the handshake between the two libraries.\n",
        "\n",
        " Converts the image from PIL to NumPy.\n",
        "\n",
        " Color Space Conversion: It converts RGB (Red-Green-Blue) to HSV (Hue-Saturation-Value).\n",
        "\n",
        " Masking: It defines a \"Green\" range and creates a binary mask (Black/White image where White = Green Object).\n",
        "\n",
        " Bitwise AND: It places the mask over the original image, effectively deleting the background.\n",
        "\n",
        " Re-conversion: It turns the result back into a PIL image so the PyTorch pipeline can continue.  \n",
        "\n",
        " kWhy HSV? In RGB, \"Green\" is a mix of three numbers. If the lighting changes (shadows), all three numbers change drastically. In HSV, the \"Color\" is just one number (Hue). This makes isolating colors much more robust against lighting changes.\n",
        "\n",
        " 3. The Pipeline Structure\n",
        "\n",
        " Class: SegmentationDataset & run_pipelineThis is standard PyTorch engineering.\n",
        "\n",
        " Dataset: Inherits from torch.utils.data.Dataset.  It essentially creates a map of your files so the computer knows how to find them.\n",
        "\n",
        " Transforms:\n",
        "\n",
        " Resize((224, 224)): Standard input size for models like ResNet or MobileNet.\n",
        "\n",
        " ToTensor(): Converts pixels (0-255) to Math Tensors (0.0-1.0).\n",
        "\n",
        " Normalize(...): Subtracts the mean and divides by standard deviation of the ImageNet dataset. This helps the AI model learn faster mathematically.\n",
        "\n",
        " DataLoader: This takes your individual images and bundles them into Batches (Groups of 4).\n",
        "\n",
        " 4. Visual Verification\n",
        "\n",
        " Block: Inside run_pipeline loop\n",
        "\n",
        " The code saves two things:\n",
        "\n",
        " 1  .pt files: The actual mathematical tensors. You feed these into a Neural Network.\n",
        "\n",
        " visual_... images: The code \"un-normalizes\" the tensor and saves a picture.\n",
        "\n",
        " Why? You cannot look at a normalized tensor; the colors will look neon and distorted. The inv_normalize step reverses the math so you can see exactly what the AI is \"seeing\"â€”which should be a green circle on a pure black background.\n",
        "\n",
        " Code Analysis & Critique\n",
        "\n",
        " Strengths:\n",
        "\n",
        " Modular: You separated data generation, transformation, and execution clearly.\n",
        "\n",
        " Robust: You handled the PIL $\\leftrightarrow$ OpenCV conversion correctly (this is a common error source).\n",
        "\n",
        " Debuggable: Saving the \"Visual\" images is a pro move. It allows you to verify your preprocessing is working before you waste hours training a model.\n",
        "\n",
        " Optimization Tips:\n",
        "\n",
        " num_workers=0: In the DataLoader, this runs everything on the main CPU process. If you set this to 2 or 4 (depending on your CPU cores), it will preprocess the next batch of images while the current batch is being processed/saved, speeding up the pipeline significantly.\n",
        "\n",
        " Hardcoded Paths: You used /content/drive/.... If you run this locally on your laptop, this will crash. It is better to use relative paths (e.g., ./data) or Python's pathlib.\n",
        "\n",
        " Summary of LogicCreate fake dirty images.\n",
        "\n",
        " Load an image.\n",
        "\n",
        " Clean the image (remove noise/background using Color Segmentation).\n",
        "\n",
        " Format the image (Resize -> Tensor -> Normalize).\n",
        "\n",
        " Batch the images.\n",
        "\n",
        " Save the result.Next StepThis code is currently set up to detect Green Circles."
      ],
      "metadata": {
        "id": "nhQnfy5GEpzN"
      }
    }
  ]
}