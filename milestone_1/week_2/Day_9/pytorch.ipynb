{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44VYCujPxl0F"
      },
      "source": [
        "### PyTorch - Deep Learning Framework\n",
        "- What is PyTorch?\n",
        "\n",
        "`PyTorch` is a deep learning framework that enables building, training, and deploying neural networks. It's the backbone for training the U-Net segmentation model in VisionExtract.\n",
        "\n",
        "- Why PyTorch for VisionExtract?\n",
        "\n",
        "  - Dynamic computation graphs: More flexible than static graphs\n",
        "\n",
        "  - Pythonic: Easy to debug and experiment with\n",
        "\n",
        "  - Production-ready: Used by major companies (Tesla, Meta, etc.)\n",
        "\n",
        "  - Ecosystem: Rich library of pre-trained models and utilities\n",
        "- #### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sw8rRj5Vws8t",
        "outputId": "84d0288b-02c7-4506-f412-28f6341e2e79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (2.9.1)\n",
            "Requirement already satisfied: torchvision in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (0.24.1)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (2.9.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from torch) (2025.7.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from torch) (80.9.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from torchvision) (2.2.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (2.9.1)\n",
            "Requirement already satisfied: torchvision in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (0.24.1)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (2.9.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from torch) (2025.7.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from torch) (80.9.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from torchvision) (2.2.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ravichandran\\onedrive\\desktop\\ml alogiritms dally progress\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "# With GPU support (CUDA 11.8)\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IecHXAcEzW_u"
      },
      "source": [
        "### 1. Tensors - PyTorch's Core Data Structure\n",
        "\n",
        "- `Tensors` are multi-dimensional arrays (similar to NumPy arrays but optimized for GPUs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6-XEpIsx9kL",
        "outputId": "6b015a35-82d9-4423-8893-f658f541d5c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zeros:\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "\n",
            "Ones:\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "\n",
            "Random:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "From NumPy:\n",
            "tensor([[ 1, 10],\n",
            "        [15,  4]])\n",
            "\n",
            "Back to NumPy:\n",
            "[[ 1 10]\n",
            " [15  4]]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Create tensors from scratch\n",
        "tensor_zeros = torch.zeros(2, 3)\n",
        "print(f\"Zeros:\\n{tensor_zeros}\")\n",
        "\n",
        "tensor_ones = torch.ones(2, 3)    # 2x3 ones\n",
        "print(f\"\\nOnes:\\n{tensor_ones}\")\n",
        "\n",
        "# Create a Python list\n",
        "tensor_from_list = torch.tensor([[1,2,3], [4,5,6]])\n",
        "print(f\"\\nRandom:\\n{tensor_from_list}\")\n",
        "\n",
        "# NumPy  PyTorch conversion\n",
        "numpy_array = np.array([[1, 10], [15, 4]])\n",
        "tensor_from_numpy = torch.from_numpy(numpy_array)\n",
        "print(f\"\\nFrom NumPy:\\n{tensor_from_numpy}\")\n",
        "\n",
        "# Back to NumPy\n",
        "back_to_numpy = tensor_from_numpy.numpy()\n",
        "print(f\"\\nBack to NumPy:\\n{back_to_numpy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTe57EZj0hYu"
      },
      "source": [
        "- #### Key Properties:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49RvI-YIzvH9",
        "outputId": "41bc505f-d8f9-418a-8030-2dc4087fabf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: torch.Size([2, 3, 224, 224])\n",
            "Data type: torch.float32\n",
            "Device: cpu\n",
            "Requires grad: False\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.randn(2 ,3 , 224, 224)  # Batch of 2 images, 3 channels, 224x224\n",
        "\n",
        "print(f\"Shape: {tensor.shape}\")        # torch.Size([2, 3, 224, 224])\n",
        "print(f\"Data type: {tensor.dtype}\")    # torch.float32\n",
        "print(f\"Device: {tensor.device}\")      # cpu or cuda\n",
        "print(f\"Requires grad: {tensor.requires_grad}\")  # False by default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVP_iHzG0rsu"
      },
      "source": [
        "#### 2. Moving Tensors to GPU\n",
        "\n",
        "  - GPUs dramatically speed up neural network training (50-100x faster)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sG7Ae8R0lOj",
        "outputId": "c4da26b1-9dcf-451d-b6ca-70c4b0ee2b06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA Availability: False\n",
            "GPU count:0\n",
            "Using device: cpu\n",
            "CPU tensor device: cpu\n",
            "GPU tensor device: cpu\n",
            "\n",
            "CPU time: 0.0211s\n",
            "GPU time: 0.0208s (including transfer overhead)\n",
            "Speedup: 1.0x\n"
          ]
        }
      ],
      "source": [
        "# Check GPU Availability\n",
        "print(f\"CUDA Availability: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU count:{torch.cuda.device_count()}\")\n",
        "if torch.cuda.is_available():\n",
        "  print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Move tensor to GPU\n",
        "tensor_cpu = torch.randn(1000, 1000)\n",
        "tensor_gpu = tensor_cpu.to(device)\n",
        "print(f\"CPU tensor device: {tensor_cpu.device}\")\n",
        "print(f\"GPU tensor device: {tensor_gpu.device}\")\n",
        "\n",
        "# GPU operations are much faster\n",
        "import time\n",
        "\n",
        "# CPU operations\n",
        "start = time.time()\n",
        "results_cpu = torch.matmul(tensor_cpu, tensor_cpu)\n",
        "cpu_time = time.time()-start\n",
        "\n",
        "# GPU operation\n",
        "start = time.time()\n",
        "result_gpu = torch.matmul(tensor_gpu, tensor_gpu)\n",
        "gpu_time = time.time() - start\n",
        "\n",
        "print(f\"\\nCPU time: {cpu_time:.4f}s\")\n",
        "print(f\"GPU time: {gpu_time:.4f}s (including transfer overhead)\")\n",
        "print(f\"Speedup: {cpu_time/gpu_time:.1f}x\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdmUexsu2xAV"
      },
      "source": [
        "#### 3. Building Neural Networks with nn.Module\n",
        "\n",
        " - `PyTorch` models are classes that inherit from nn.Module. This is the standard way to define neural networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt4p4QIP1KFZ",
        "outputId": "b72ff14d-7b32-4cfd-a287-8396dbc8bd71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([32, 784])\n",
            "Output shape: torch.Size([32, 10])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Simple Neural Network\n",
        "class SimpleNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(SimpleNet, self).__init__()\n",
        "\n",
        "    # Define layers\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size) # Input -> Hidden\n",
        "    self.relu = nn.ReLU() # Activation\n",
        "    self.sigmoid = nn.Sigmoid() # Activation \n",
        "    self.fc2 = nn.Linear(hidden_size, num_classes) # Hidden -> Ouput\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"Forward pass: defines how data flows through the network\"\"\"\n",
        "    x = self.fc1(x)  # Linear layer\n",
        "    x = self.relu(x) # ReLU activation\n",
        "    x = self.sigmoid(x) # Sigmoid activation \n",
        "    x = self.fc2(x) # Output layer\n",
        "    return x\n",
        "\n",
        "# Create model instance\n",
        "model = SimpleNet(input_size=784, hidden_size=128, num_classes=10)\n",
        "\n",
        "# Test forward pass\n",
        "dummy_input = torch.randn(32, 784)  # Batch of 32 images, 784 features\n",
        "output = model(dummy_input)\n",
        "print(f\"Input shape: {dummy_input.shape}\")\n",
        "print(f\"Output shape: {output.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input range: -0.42136189341545105 to 0.8286473155021667\n",
            "\n",
            "ReLU        : 0.023503\n",
            "LeakyReLU   : 0.051662\n",
            "Tanh        : -0.392495\n",
            "Sigmoid     : -0.062478\n",
            "ELU         : -0.393911\n",
            "GELU        : 0.703459\n"
          ]
        }
      ],
      "source": [
        "def properly_test_activations():\n",
        "    # Set random seed for reproducibility\n",
        "    torch.manual_seed(42)\n",
        "    \n",
        "    # Create normalized input\n",
        "    x = torch.randn(1, 10)  # Batch size 1, 10 features\n",
        "    x = F.normalize(x, dim=1)  # Normalize\n",
        "    \n",
        "    print(\"Input range:\", x.min().item(), \"to\", x.max().item())\n",
        "    print()\n",
        "    \n",
        "    # Test different activations\n",
        "    activations = {\n",
        "        'ReLU': nn.ReLU(),\n",
        "        'LeakyReLU': nn.LeakyReLU(0.1),\n",
        "        'Tanh': nn.Tanh(),\n",
        "        'Sigmoid': nn.Sigmoid(),\n",
        "        'ELU': nn.ELU(),\n",
        "        'GELU': nn.GELU()\n",
        "    }\n",
        "    \n",
        "    for name, activation in activations.items():\n",
        "        # Create fresh model each time\n",
        "        model = nn.Sequential(\n",
        "            nn.Linear(10, 5),\n",
        "            activation,\n",
        "            nn.Linear(5, 1)\n",
        "        )\n",
        "        \n",
        "        # Reinitialize weights\n",
        "        for layer in model:\n",
        "            if hasattr(layer, 'weight'):\n",
        "                nn.init.xavier_uniform_(layer.weight)\n",
        "                nn.init.zeros_(layer.bias)\n",
        "        \n",
        "        output = model(x)\n",
        "        print(f\"{name:12}: {output.item():.6f}\")\n",
        "\n",
        "# Run the test\n",
        "properly_test_activations()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKXSqDi84Uqa"
      },
      "source": [
        "- Teaching Point: Show the architecture:\n",
        "\n",
        "Input (32, 784)\n",
        "\n",
        "    ↓\n",
        "\n",
        "Linear(784 → 128)\n",
        "\n",
        "    ↓\n",
        "\n",
        "ReLU\n",
        "\n",
        "    ↓\n",
        "\n",
        "Linear(128 → 10)\n",
        "\n",
        "    ↓\n",
        "    \n",
        "Output (32, 10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ank ss (Python 3.12.7)",
      "language": "python",
      "name": "ank-ss"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
